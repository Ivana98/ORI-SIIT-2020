12th TRIAL
-------------------------------

### CODE:

EPOCHS = 30

model = Sequential()
model.add(Conv2D(64, kernel_size=(3, 3), input_shape=(IMG_W, IMG_H, 3)))
model.add(Activation("relu"))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(64, kernel_size=(3, 3)))
model.add(Activation("sigmoid"))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(128, kernel_size=(3, 3)))
model.add(Activation("relu"))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(128, kernel_size=(3, 3)))
model.add(Activation("sigmoid"))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Flatten())
model.add(Dense(128, activation="relu", kernel_regularizer=keras.regularizers.l2(0.001)))
model.add(Dense(64, kernel_regularizer=keras.regularizers.l2(0.001)))
model.add(Dense(NUM_OF_CLASSES, activation="softmax"))


### RESULT:

Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d (Conv2D)              (None, 62, 62, 64)        1792      
_________________________________________________________________
activation (Activation)      (None, 62, 62, 64)        0         
_________________________________________________________________
batch_normalization (BatchNo (None, 62, 62, 64)        256       
_________________________________________________________________
max_pooling2d (MaxPooling2D) (None, 31, 31, 64)        0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 29, 29, 64)        36928     
_________________________________________________________________
activation_1 (Activation)    (None, 29, 29, 64)        0         
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 14, 14, 64)        0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 12, 12, 128)       73856     
_________________________________________________________________
activation_2 (Activation)    (None, 12, 12, 128)       0         
_________________________________________________________________
batch_normalization_1 (Batch (None, 12, 12, 128)       512       
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 6, 6, 128)         0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 4, 4, 128)         147584    
_________________________________________________________________
activation_3 (Activation)    (None, 4, 4, 128)         0         
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 2, 2, 128)         0         
_________________________________________________________________
flatten (Flatten)            (None, 512)               0         
_________________________________________________________________
dense (Dense)                (None, 128)               65664     
_________________________________________________________________
dense_1 (Dense)              (None, 64)                8256      
_________________________________________________________________
dense_2 (Dense)              (None, 3)                 195       
=================================================================

Total params: 335,043
Trainable params: 334,659
Non-trainable params: 384
_________________________________________________________________
Epoch 1/30
116/116 [==============================] - 93s 806ms/step - loss: 0.9687 - accuracy: 0.6780 - val_loss: 1.2323 - val_accuracy: 0.4893
Epoch 2/30
116/116 [==============================] - 96s 823ms/step - loss: 0.8329 - accuracy: 0.7343 - val_loss: 1.7998 - val_accuracy: 0.4792
Epoch 3/30
116/116 [==============================] - 94s 810ms/step - loss: 0.7741 - accuracy: 0.7557 - val_loss: 1.9021 - val_accuracy: 0.4792
Epoch 4/30
116/116 [==============================] - 95s 822ms/step - loss: 0.7338 - accuracy: 0.7714 - val_loss: 2.2144 - val_accuracy: 0.4358
Epoch 5/30
116/116 [==============================] - 94s 811ms/step - loss: 0.7202 - accuracy: 0.7735 - val_loss: 1.3298 - val_accuracy: 0.5031
Epoch 6/30
116/116 [==============================] - 94s 815ms/step - loss: 0.6923 - accuracy: 0.7892 - val_loss: 0.9269 - val_accuracy: 0.6461
Epoch 7/30
116/116 [==============================] - 95s 821ms/step - loss: 0.6826 - accuracy: 0.7881 - val_loss: 0.7774 - val_accuracy: 0.7336
Epoch 8/30
116/116 [==============================] - 95s 816ms/step - loss: 0.6736 - accuracy: 0.7911 - val_loss: 1.0441 - val_accuracy: 0.6077
Epoch 9/30
116/116 [==============================] - 94s 808ms/step - loss: 0.6382 - accuracy: 0.8049 - val_loss: 0.6988 - val_accuracy: 0.7557
Epoch 10/30
116/116 [==============================] - 95s 820ms/step - loss: 0.6321 - accuracy: 0.8019 - val_loss: 0.9106 - val_accuracy: 0.6839
Epoch 11/30
116/116 [==============================] - 95s 816ms/step - loss: 0.6119 - accuracy: 0.8014 - val_loss: 0.7928 - val_accuracy: 0.7065
Epoch 12/30
116/116 [==============================] - 98s 842ms/step - loss: 0.5986 - accuracy: 0.8052 - val_loss: 0.7748 - val_accuracy: 0.7072
Epoch 13/30
116/116 [==============================] - 95s 819ms/step - loss: 0.5919 - accuracy: 0.8101 - val_loss: 0.9102 - val_accuracy: 0.6612
Epoch 14/30
116/116 [==============================] - 94s 811ms/step - loss: 0.5861 - accuracy: 0.8093 - val_loss: 0.7400 - val_accuracy: 0.7317
Epoch 15/30
116/116 [==============================] - 98s 845ms/step - loss: 0.5829 - accuracy: 0.8052 - val_loss: 0.8376 - val_accuracy: 0.6518
Epoch 16/30
116/116 [==============================] - 97s 839ms/step - loss: 0.5617 - accuracy: 0.8125 - val_loss: 0.6950 - val_accuracy: 0.7336
Epoch 17/30
116/116 [==============================] - 98s 847ms/step - loss: 0.5538 - accuracy: 0.8144 - val_loss: 0.9034 - val_accuracy: 0.6612
Epoch 18/30
116/116 [==============================] - 98s 841ms/step - loss: 0.5470 - accuracy: 0.8220 - val_loss: 0.7569 - val_accuracy: 0.7034
Epoch 19/30
116/116 [==============================] - 96s 828ms/step - loss: 0.5408 - accuracy: 0.8179 - val_loss: 0.8929 - val_accuracy: 0.6499
Epoch 20/30
116/116 [==============================] - 95s 821ms/step - loss: 0.5282 - accuracy: 0.8239 - val_loss: 0.7113 - val_accuracy: 0.7147
Epoch 21/30
116/116 [==============================] - 96s 824ms/step - loss: 0.5206 - accuracy: 0.8260 - val_loss: 0.7047 - val_accuracy: 0.7273
Epoch 22/30
116/116 [==============================] - 95s 816ms/step - loss: 0.5211 - accuracy: 0.8266 - val_loss: 0.8859 - val_accuracy: 0.5812
Epoch 23/30
116/116 [==============================] - 96s 825ms/step - loss: 0.5287 - accuracy: 0.8157 - val_loss: 1.1802 - val_accuracy: 0.5516
Epoch 24/30
116/116 [==============================] - 95s 820ms/step - loss: 0.5000 - accuracy: 0.8309 - val_loss: 0.7507 - val_accuracy: 0.7021
Epoch 25/30
116/116 [==============================] - 95s 819ms/step - loss: 0.4825 - accuracy: 0.8393 - val_loss: 0.7312 - val_accuracy: 0.7110
Epoch 26/30
116/116 [==============================] - 95s 821ms/step - loss: 0.4767 - accuracy: 0.8369 - val_loss: 0.6708 - val_accuracy: 0.7173
Epoch 27/30
116/116 [==============================] - 94s 813ms/step - loss: 0.4787 - accuracy: 0.8290 - val_loss: 1.1006 - val_accuracy: 0.5718
Epoch 28/30
116/116 [==============================] - 94s 811ms/step - loss: 0.4695 - accuracy: 0.8404 - val_loss: 0.9250 - val_accuracy: 0.6870
Epoch 29/30
116/116 [==============================] - 95s 815ms/step - loss: 0.4692 - accuracy: 0.8377 - val_loss: 1.0367 - val_accuracy: 0.6297
Epoch 30/30
116/116 [==============================] - 94s 813ms/step - loss: 0.4601 - accuracy: 0.8387 - val_loss: 0.7570 - val_accuracy: 0.6719
20/20 [==============================] - 8s 397ms/step - loss: 0.6860 - accuracy: 0.7965
Tested:
[0.685989499092102, 0.7964743375778198]

Start Time = 00:22:29
End Time = 01:10:39
Duration:  0:48:10.000751


# Same code as 10th trial, different number of epochs.